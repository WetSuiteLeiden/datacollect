{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, pprint, collections, random\n",
    "import wetsuite.datasets\n",
    "import wetsuite.helpers.patterns\n",
    "import wetsuite.helpers.etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwb  = wetsuite.datasets.load('bwb-mostrecent-xml').data\n",
    "cvdr = wetsuite.datasets.load('cvdr-mostrecent-xml').data\n",
    "rsnl = wetsuite.datasets.load('rechtspraaknl-struc').data\n",
    "# TODO: even more free-flowing text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find things that look ECLI-like, to create test data\n",
    "\n",
    "...test data for the ECLI parsing code, that is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrefs     = 0\n",
    "mostrefs_url = ''\n",
    "\n",
    "# create a text file where each line contains\n",
    "# - ECLI identifier text with possible muck after it\n",
    "# - tab character\n",
    "# - URL of the document this was found in   (CONSIDER: also adding offset)\n",
    "with open('eclitest.txt','w') as eclitestfile:\n",
    "    \n",
    "    # this goes through a few gigabytes of text, will take order of ten minutes\n",
    "    for store in ( #easier to skip one with comments this way\n",
    "        bwb, \n",
    "        cvdr,\n",
    "        rsnl,\n",
    "    ):\n",
    "        for i, (url, data) in enumerate( store.items() ):\n",
    "            # this deals with the fact that one of the datasets gives us python dicts, and the other two XML bytestrings.\n",
    "            #   note that both of these cases can be made cleaner (at some speed cost)\n",
    "            if isinstance(data, dict): # assume rechtspraak\n",
    "                data = str(data)  # quick and dirty way to make that a string to search in \n",
    "            else: # assume it's a bytes object\n",
    "                data = data.decode('utf8') # we don't parse these\n",
    "                \n",
    "            # this regexp awkwardly tries to accept more, without too much nonsense  (definitely _some_ nonsense, though)\n",
    "            matches = list( re.finditer(r'(?<!:)([eECc][a-zA-Z]+[:](?:[^\\s]{1,10}[:]){2,7}[^\\s]+)', data) ) #intentionally overaccepts at the end\n",
    "            if len(matches) > 1:\n",
    "                for match_object in matches:\n",
    "                    txt = match_object.group(0)\n",
    "                    if 'jci' in txt:\n",
    "                        continue\n",
    "                    msg = f'{txt}\\t{url}\\n'\n",
    "                    eclitestfile.write( msg )                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a subset of that ECLI test data \n",
    "\n",
    "Try to parse each ECLI to see if it seems valid, to sort this into probably-good and probably-bad ECLIs.\n",
    "\n",
    "We also have _loads_ of good examples and don't need that many, \n",
    "so we creat shorter test lists via a random sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_str = collections.defaultdict(int)\n",
    "#count_bad     = 0\n",
    "\n",
    "good = []\n",
    "bad  = []\n",
    "\n",
    "with open('eclitest.txt','r') as eclitestfile:\n",
    "    for line in eclitestfile:\n",
    "        text, url = line.rstrip('\\n').rsplit('\\t', 1)\n",
    "        \n",
    "        try:\n",
    "            parsed = wetsuite.helpers.meta.parse_ecli(text)\n",
    "            #if parsed['country_code'].upper()=='NL':\n",
    "            #    cc = parsed['court_code']\n",
    "            #    if wetsuite.extras.gerechtcodes.case_insensitive_lookup(cc) is None:\n",
    "            #        count_str[cc] += 1\n",
    "            good.append( (text, url) )\n",
    "        except ValueError as ve:\n",
    "            bad.append( (text, url) )\n",
    "            #count_bad += 1\n",
    "            #count_str[text.split(':')[0]] += 1\n",
    "            print(text, ve, url) # currently spits out ~25K complaints, so consider commenting this out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "974016 25843\n"
     ]
    }
   ],
   "source": [
    "print( len(good), len(bad) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ecli_good.txt','w') as good_ecli_file:\n",
    "    for text, url in sorted(random.sample(good, 20000)):\n",
    "        good_ecli_file.write(f'{text}\\t{url}\\n')\n",
    "\n",
    "with open('ecli_bad.txt','w') as bad_ecli_file:\n",
    "    for text, url in sorted(random.sample(bad, 20000)):\n",
    "        bad_ecli_file.write(f'{text}\\t{url}\\n')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
